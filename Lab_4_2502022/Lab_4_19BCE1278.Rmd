---
title: "PCA and LDA"
subtitle: "Reg no : 19BCE1278"
author: "Name : Anish Sarkar"
date: "Date : 01/03/2022"
output: html_document
---

# PCA

1. Use Breast Cancer Wisconsin data set from the UCI Machine learning repo to plot the PCA analysis. Use the ‘prcomp’ function runs PCA on the data.

i. You want to explain difference between malignant and benign tumors using Visualisation and add the response variable (diagnosis) to the plot

ii. Construct some kind of model using the first 6 principal components to predict whether a tumor is benign or malignant and then compare it to a model using the original 30 variables. 


```{r}
data <- read.csv('breast-cancer-data.csv')
data <- data[c(1:32)]
head(data)
ncol(data)
```

```{r}
data_pca <- prcomp(data[,c(3:32)], center = TRUE,scale. = TRUE)
str(data_pca)
```

```{r}
library(devtools)
library(ggbiplot)
ggbiplot(data_pca)
```


```{r}
cumpro <- cumsum(data_pca$sdev^2 / sum(data_pca$sdev^2))
plot(cumpro[0:15], xlab = "PC #", ylab = "Amount of explained variance", main = "Cumulative variance plot")
plot(data_pca$x[,1],data_pca$x[,2], xlab="PC1 (44.3%)", ylab = "PC2 (19%)", main = "PC1 / PC2 - plot")
```

```{r}
pca_br_cancer <- data.frame(
  pc1 = data_pca$x[,1],
  pc2 = data_pca$x[,2],
  diagnosis = data$diagnosis
)

pca_br_cancer
```

## With 30 principle components

```{r}
library(ggplot2)
summary(data_pca)
screeplot(data_pca, type = "l", npcs = 30, main = "Screeplot of the 30 PCs")
ggplot(pca_br_cancer, aes(pc1, pc2)) + geom_point(aes(color = diagnosis))
```

## With 6 principle components

```{r}
data_pca_6 <- prcomp(data[,c(3:8)], center = TRUE,scale. = TRUE)
summary(data_pca_6)
pca_br_cancer_6 <- data.frame(
  pc1 = data_pca$x[,1],
  pc2 = data_pca$x[,2],
  diagnosis = data$diagnosis
)
ggbiplot(data_pca_6)
screeplot(data_pca_6, type = "l", npcs = 6, main = "Screeplot of the 6 PCs")

ggplot(pca_br_cancer_6, aes(pc1, pc2)) + geom_point(aes(color = diagnosis))
```

## Variance in 6th princple component for the model with 30 principle components is about 1.09. But the 6th principle component for the model with 6 principle components is close to 0 ( about 0.017).

# LDA

2. Use the built-in iris dataset in R to plot the LDA analysis. Use the lda function of the MASS package in R

Project the LDA visual output and Compare the LDA and PCA 2D Projection of Iris dataset

```{r}
data("iris")
head(iris)
nrow(iris)
```

```{r}
library(MASS)
lda1 <- lda(Species ~ ., data = iris, prior = c(1,1,1)/3)
lda1$prior
lda1$counts
lda1$means
lda1$scaling
lda1$svd
prop = lda1$svd^2/sum(lda1$svd^2)
prop

```

```{r}
lda2 <- lda(Species ~ ., data = iris, prior = c(1,1,1)/3, CV = TRUE)
head(lda2$class)
head(lda2$posterior, 3)
train <- sample(1:150, 75)
lda3 <- lda(Species ~ ., data = iris, prior = c(1,1,1)/3, subset = train)
lda3
plda = predict(object = lda1, # predictions
               newdata = iris[-train, ])
plda
```

```{r}
head(plda$class) # classification result
head(plda$posterior, 3)
head(plda$x, 3) # LD projections
```


```{r}
plda_plot <- cbind(train, predict(lda3)$x)
plda_plot
plda_df <- data.frame(plda_plot)
plda_df
# plda_df$Species <- iris$Species
# plda_df
```



```{r}
# iris[c(1:4)]
iris_pca <- prcomp(iris[,c(1:4)], center = TRUE,scale. = TRUE)
```


```{r}
pca_df <- data.frame(
  pc1 = iris_pca$x[,1],
  pc2 = iris_pca$x[,2],
  Species = iris$Species
)

head(pca_df)
```

## 2D LDA

```{r}
library(ggplot2)
ggplot(plda_df, aes(LD1, LD2)) + geom_point(aes(color = iris$Species[train]))
```

## 2D PCA

```{r}
ggplot(pca_df, aes(pc1, pc2)) + geom_point(aes(color = Species))
```

